{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuccUQ+ixS7utsFkGOyHYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisisZAQ/Decoding-Fiscal-Narratives-A-20-Year-NLP-Study-of-India-s-Union-Budgets/blob/main/Budget_Speeches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gettng Started**"
      ],
      "metadata": {
        "id": "oMV-FDmc56FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/Speech_20years.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Clean the column names by stripping extra spaces\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Drop rows with missing speech data and group by Year and Finance Minister\n",
        "df_cleaned = df[['Year', 'Minister', 'Speech']].dropna()\n",
        "df_grouped = df_cleaned.groupby(['Year', 'Minister'])['Speech'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "jjZLkDEoUG2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of each speech in words\n",
        "df_grouped['Speech Length'] = df_grouped['Speech'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Group by Finance Minister and calculate the total speech length for each minister\n",
        "speech_length_by_minister = df_grouped.groupby('Minister')['Speech Length'].sum().reset_index()\n",
        "\n",
        "# Sort by speech length for better visualization\n",
        "speech_length_by_minister = speech_length_by_minister.sort_values(by='Speech Length', ascending=False)\n",
        "\n",
        "# Display the results\n",
        "speech_length_by_minister.head()\n"
      ],
      "metadata": {
        "id": "Wx6EVYi4aRTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of each speech in words\n",
        "df_grouped['Speech Length'] = df_grouped['Speech'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Group by Finance Minister and calculate the total speech length for each minister\n",
        "speech_length_by_minister = df_grouped.groupby('Minister')['Speech Length'].sum().reset_index()\n",
        "\n",
        "# Sort by speech length for better visualization\n",
        "speech_length_by_minister = speech_length_by_minister.sort_values(by='Speech Length', ascending=False)\n",
        "\n",
        "# Display the results\n",
        "speech_length_by_minister.head()\n",
        "\n",
        "df_grouped.tail()\n",
        "speech_length_by_minister.head()\n"
      ],
      "metadata": {
        "id": "IpsvF2DxUvaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='Year', y='Speech Length', data=df_grouped, marker='o')\n",
        "plt.title('Speech Length Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Words')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KVBwbpPHKkHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create the bar plot using Plotly Express\n",
        "fig = px.bar(speech_length_by_minister,\n",
        "             x='Speech Length',\n",
        "             y='Minister',\n",
        "             orientation='h',  # Horizontal bar plot\n",
        "             title='Total Speech Length by Finance Minister',\n",
        "             labels={'Speech Length': 'Speech Length (Word Count)', 'Minister': 'Minister'},\n",
        "             color='Speech Length',  # Color based on speech length\n",
        "            template='plotly_dark',\n",
        "             color_continuous_scale='Viridis')\n",
        "\n",
        "# Customize layout (optional)\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Total Speech Length (Word Count)\",\n",
        "    yaxis_title=\"Finance Minister\",\n",
        "    height=600,\n",
        "    width=900\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mTC-13BUUz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wordcloud"
      ],
      "metadata": {
        "id": "q9PnL6gDWfX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Combine all speeches into one large text\n",
        "all_text = ' '.join(df_grouped['Speech'])\n",
        "\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O-IgvP1JWiaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the spaCy language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Visualize named entities for the first speech\n",
        "doc = nlp(df_grouped['Speech'][3])\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ltKGuFUGuuVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define themes and associated keywords\n",
        "themes = {\n",
        "    'inflation': ['inflation', 'prices', 'cost of living'],\n",
        "    'tax': ['tax', 'taxation', 'income tax', 'corporate tax','tax bracket','tax slabs'],\n",
        "    'growth': ['growth', 'development', 'GDP', 'economy','globalisation'],\n",
        "    'employment': ['employment', 'jobs', 'unemployment','MSME','MSMEs'],\n",
        "    'budget': ['deficit', 'surplus', 'expenditure'],\n",
        "    'education': ['education', 'schools', 'youth','children','primary education','secondary education'],\n",
        "    'defence': ['defence', 'national', 'security','threat'],\n",
        "    'poverty' : ['poverty','poverty line','poor'],\n",
        "    'women' :['women','women empowerment','women led','women participation','girl child']\n",
        "}\n"
      ],
      "metadata": {
        "id": "dDnDsblKXYT6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to count keyword occurrences for a specific theme\n",
        "def count_keywords(speech, keywords):\n",
        "    count = 0\n",
        "    for keyword in keywords:\n",
        "        count += len(re.findall(r'\\b' + re.escape(keyword) + r'\\b', speech.lower()))\n",
        "    return count\n",
        "\n",
        "# Add columns for each theme, counting the occurrences of theme-related words\n",
        "for theme, keywords in themes.items():\n",
        "    df_grouped[theme] = df_grouped['Speech'].apply(lambda x: count_keywords(x, keywords))\n",
        "\n",
        "# Display the dataframe with theme counts\n",
        "df_grouped.head()\n",
        "df_grouped.info()\n",
        "df_grouped.to_csv('speech_with_theme_counts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "oXMaxSgHXZe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Group by Finance Minister and sum the keyword counts for each theme\n",
        "theme_counts_by_minister = df_grouped.groupby('Minister')[list(themes.keys())].sum().reset_index()\n",
        "\n",
        "# Melt the DataFrame to make it long-form for easier plotting\n",
        "theme_counts_melted = theme_counts_by_minister.melt(id_vars='Minister', var_name='Theme', value_name='Count')\n",
        "\n",
        "# Plot the theme mentions using Plotly Express\n",
        "fig = px.bar(theme_counts_melted,\n",
        "             x='Minister',\n",
        "             y='Count',\n",
        "             color='Theme',\n",
        "              color_discrete_sequence=px.colors.qualitative.T10,\n",
        "             title='Theme Mentions by Finance Minister',\n",
        "             labels={'Count': 'Number of Mentions', 'Minister': 'Finance Minister'},\n",
        "             barmode='group',\n",
        "             template='plotly_dark')\n",
        "\n",
        "# Customize layout\n",
        "fig.update_layout(xaxis_title='Finance Minister', yaxis_title='Number of Mentions', height=600, width=1000)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "U3olsOFhXhJF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Plot the theme mentions using a stacked bar chart\n",
        "fig = px.bar(theme_counts_melted,\n",
        "             x='Minister',\n",
        "             y='Count',\n",
        "             color='Theme',\n",
        "             title='Comparison of Themes by Finance Minister',\n",
        "             labels={'Count': 'Number of Mentions', 'Name of Finance Minister': 'Finance Minister'},\n",
        "             barmode='stack',\n",
        "             template='plotly_dark') # Use 'stack' to create a stacked bar chart\n",
        "\n",
        "fig.update_layout(xaxis_title='Finance Minister', yaxis_title='Number of Mentions', height=600, width=1000)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "44j0D98eYYJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "T_2UHTrN6dqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas spacy gensim pyLDAvis\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "55Sh70Jd6dVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.corpora import Dictionary\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Load spaCy model for lemmatization\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to preprocess text (tokenization, lemmatization, stopwords removal)\n",
        "def preprocess(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "    return tokens\n",
        "\n",
        "# Define custom stopwords (domain-specific words)\n",
        "custom_stopwords = ['cent', 'crore', 'propose', 'year', 'sector', 'government', 'duty', 'lakh','rate','shall','new','high','provide','rs']\n",
        "\n",
        "# Load the spaCy model and extend its stopwords\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "for word in custom_stopwords:\n",
        "    nlp.vocab[word].is_stop = True\n",
        "\n",
        "# Apply preprocessing to each speech\n",
        "df_grouped['tokens'] = df_grouped['Speech'].apply(preprocess)\n",
        "\n",
        "# Create a Gensim dictionary and corpus\n",
        "dictionary = Dictionary(df_grouped['tokens'])\n",
        "corpus = [dictionary.doc2bow(text) for text in df_grouped['tokens']]\n",
        "\n",
        "# Display the processed tokens and corpus\n",
        "print(dictionary)\n",
        "print(corpus[:1])  # Display the first document's bag of words\n"
      ],
      "metadata": {
        "id": "JASFb0OA6pGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of topics (you can adjust this based on the results)\n",
        "num_topics = 5\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=10, random_state=42)\n",
        "\n",
        "# Print the topics with words\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "id": "kjEwdrXu69vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "# Prepare the pyLDAvis visualization\n",
        "lda_display = gensimvis.prepare(lda_model, corpus, dictionary, sort_topics=False)\n",
        "\n",
        "# Display the visualization in\n",
        "pyLDAvis.display(lda_display)\n"
      ],
      "metadata": {
        "id": "34offoYC7CDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis"
      ],
      "metadata": {
        "id": "ukPff_vbSrfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dCvbAsp3alVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n"
      ],
      "metadata": {
        "id": "P3ZLZ2jLSvTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (replace 'path_to_your_budget_file.csv' with your actual file path)\n",
        "df_senti = pd.read_csv('/content/Speech_20years.csv')\n",
        "\n",
        "# Clean the column names if needed\n",
        "#df_senti.columns = df.columns.str.strip()\n",
        "# Replace NaN values in the 'Speech' column with an empty string\n",
        "df_senti['Speech'] = df['Speech'].fillna('')\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df_senti.head()"
      ],
      "metadata": {
        "id": "vsijKHjqThIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "# Replace NaN values in the 'Speech' column with an empty string\n",
        "df['Speech'] = df['Speech'].fillna('')\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to calculate sentiment for each speech\n",
        "def get_sentiment(text):\n",
        "    return analyzer.polarity_scores(text)\n",
        "\n",
        "# sentiment analysis to each speech\n",
        "df_senti['Sentiment'] = df['Speech'].apply(lambda speech: get_sentiment(speech))\n",
        "\n",
        "# Split the VADER sentiment into individual columns\n",
        "df_sentiment = df_senti['Sentiment'].apply(pd.Series)\n",
        "\n",
        "# Merge the sentiment scores back into the original dataframe\n",
        "df = pd.concat([df_senti, df_sentiment], axis=1)\n",
        "\n",
        "# Display the updated dataframe with sentiment scores\n",
        "df.head()\n",
        "df.tail()\n",
        "df['Year']\n"
      ],
      "metadata": {
        "id": "6tkI11XvTyKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the starting year from the 'Year' column\n",
        "df['Year'] = df['Year'].astype(str).str.split('-').str[0]\n",
        "\n",
        "# Convert the 'Year' column to numeric\n",
        "df['Year'] = df['Year'].astype(str).str.split('-').str[0]\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "\n"
      ],
      "metadata": {
        "id": "DrfE8RImJvRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average sentiment score for each year\n",
        "sentiment_over_time = df.groupby('Year')['compound'].mean().reset_index()\n",
        "\n",
        "# Ensure the 'Year' column is sorted numerically\n",
        "sentiment_over_time = sentiment_over_time.sort_values('Year')\n",
        "\n",
        "# Plot the line chart for sentiment over time\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(sentiment_over_time,\n",
        "              x='Year',\n",
        "              y='compound',\n",
        "              title='Sentiment of Budget Speeches Over Time',\n",
        "              labels={'compound': 'Sentiment Score', 'Year': 'Year'},\n",
        "              template='plotly_dark')\n",
        "\n",
        "fig.update_layout(xaxis_title='Year', yaxis_title='Average Sentiment Score')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "4hKtSJTDK1S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average sentiment score for each finance minister\n",
        "sentiment_by_minister = df.groupby('Minister')['compound'].mean().reset_index()\n",
        "\n",
        "fig = px.bar(sentiment_by_minister,\n",
        "             x='Minister',\n",
        "             y='compound',\n",
        "             title='Average Sentiment by Finance Minister',\n",
        "             labels={'compound': 'Sentiment Score', 'Minister': 'Finance Minister'},\n",
        "            template='plotly_dark')\n",
        "\n",
        "fig.update_layout(xaxis_title='Finance Minister', yaxis_title='Average Sentiment Score')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Wc9plyIXVJCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER VISULISATION"
      ],
      "metadata": {
        "id": "uYJIwoY0c31q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Load your budget speeches dataset\n",
        "df = pd.read_csv('/content/Speech_20years.csv')\n",
        "df['Year'] = df['Year'].astype(str).str.split('-').str[0]\n",
        "df['Speech'] = df['Speech'].fillna('')\n",
        "# Function to extract named entities\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]  # Extract entity text and label\n",
        "    return entities\n",
        "\n",
        "# Apply the function to extract entities\n",
        "df['Entities'] = df['Speech'].apply(extract_entities)\n",
        "\n",
        "# Create a dataframe of entity mentions per speech\n",
        "entity_data = []\n",
        "for index, row in df.iterrows():\n",
        "    for entity, label in row['Entities']:\n",
        "        entity_data.append({'Year': row['Year'], 'Entity': entity, 'Label': label})\n",
        "\n",
        "entity_df = pd.DataFrame(entity_data)\n"
      ],
      "metadata": {
        "id": "Fy3i-v3Fc9_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the frequency of each entity label over time\n",
        "entity_counts = entity_df.groupby(['Year', 'Label']).size().reset_index(name='Count')\n",
        "\n",
        "# Optional: Filter for the top N most common entity types (e.g., ORG, GPE, DATE)\n",
        "top_entity_labels = entity_counts.groupby('Label')['Count'].sum().nlargest(5).index\n",
        "entity_counts = entity_counts[entity_counts['Label'].isin(top_entity_labels)]\n"
      ],
      "metadata": {
        "id": "_PWXxJN9eLng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a line chart to show how entity mentions changed over time\n",
        "fig = px.line(entity_counts,\n",
        "              x='Year',\n",
        "              y='Count',\n",
        "              color='Label',\n",
        "              title='Entity Mentions Over Time',\n",
        "              labels={'Count': 'Number of Mentions', 'Year': 'Year', 'Label': 'Entity Type'})\n",
        "\n",
        "# Customize the chart\n",
        "fig.update_layout(\n",
        "    xaxis_title='Year',\n",
        "    yaxis_title='Number of Mentions',\n",
        "    template='plotly_dark',\n",
        "    paper_bgcolor='#2B2B2B',\n",
        "    plot_bgcolor='#2B2B2B',\n",
        "    font_color='white'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "vxjrhjG0eQCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract organizations (ORG) from speeches\n",
        "def extract_orgs(text):\n",
        "    doc = nlp(text)\n",
        "    orgs = [ent.text for ent in doc.ents if ent.label_ == 'ORG']  # Extract only organizations (ORG)\n",
        "    return orgs\n",
        "\n",
        "# Apply the function to extract organizations from each speech\n",
        "df['Organizations'] = df['Speech'].apply(extract_orgs)\n",
        "\n",
        "# Create a dataframe of organization mentions per speech\n",
        "org_data = []\n",
        "for index, row in df.iterrows():\n",
        "    for org in row['Organizations']:\n",
        "        org_data.append({'Year': row['Year'], 'Organization': org})\n",
        "\n",
        "org_df = pd.DataFrame(org_data)\n",
        "\n",
        "# Count the number of times each organization is mentioned per year\n",
        "org_counts = org_df.groupby(['Year', 'Organization']).size().reset_index(name='Count')\n",
        "\n",
        "# Optional: Filter for the top N organizations mentioned most frequently\n",
        "top_orgs = org_counts.groupby('Organization')['Count'].sum().nlargest(10).index\n",
        "org_counts = org_counts[org_counts['Organization'].isin(top_orgs)]\n"
      ],
      "metadata": {
        "id": "6fdQU6W26EbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create a bar chart showing how many times each organization is mentioned over time\n",
        "fig = px.bar(org_counts,\n",
        "             x='Year',\n",
        "             y='Count',\n",
        "             color='Organization',\n",
        "             title='Organization Mentions Over Time',\n",
        "             labels={'Count': 'Number of Mentions', 'Year': 'Year', 'Organization': 'Organization'},\n",
        "             barmode='group')\n",
        "\n",
        "# Customize the chart (dark theme)\n",
        "fig.update_layout(\n",
        "    xaxis_title='Year',\n",
        "    yaxis_title='Number of Mentions',\n",
        "    template='plotly_dark',\n",
        "    paper_bgcolor='#2B2B2B',\n",
        "    plot_bgcolor='#2B2B2B',\n",
        "    font_color='white'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "GCHtwbLz6unK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shifting policies over time"
      ],
      "metadata": {
        "id": "8or8t-SJkLBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Load your budget speeches dataset (replace with your file path)\n",
        "df = pd.read_csv('/content/Speech_20years.csv')\n",
        "df['Speech'] = df['Speech'].fillna('')\n",
        "\n",
        "# Clean column names (if necessary)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Ensure year is properly formatted\n",
        "df['Year'] = df['Year'].astype(str).str.split('-').str[0]\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize PhraseMatcher and define patterns for organization names\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "# Define the list of organizations you want to match\n",
        "organization_list = [\"Swachh Bharat\", \"Digital India\", \"Make in India\", \"National Rural Employment Guarantee Scheme\",\n",
        "                     \"Smart Cities\", \"Sarva Siksha Abhiyan\", \"Viksit Bharat\",\"Pradhan Mantri Jan Dhan Yojana\",\"Atmanirbhar Bharat\",\n",
        "                     \"Pradhan Mantri Awas Yojana- Grami\",\"PM GatiShakti\"]\n",
        "\n",
        "# Create phrase patterns for the organizations\n",
        "patterns = [nlp(org) for org in organization_list]\n",
        "matcher.add(\"ORG\", patterns)\n",
        "\n",
        "# Function to extract matched organizations from the speech\n",
        "def extract_custom_entities(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    orgs = [doc[start:end].text for match_id, start, end in matches]\n",
        "    return orgs\n",
        "\n",
        "# Apply the custom entity extraction function to each speech\n",
        "df['Organizations'] = df['Speech'].apply(extract_custom_entities)\n",
        "\n",
        "# Check results\n",
        "df[['Speech', 'Organizations']].head()\n"
      ],
      "metadata": {
        "id": "i6bZDK7erjNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate organization frequencies by year\n",
        "org_frequency = pd.DataFrame()\n",
        "\n",
        "for org in organization_list:\n",
        "    df[org + '_count'] = df['Organizations'].apply(lambda x: x.count(org))\n",
        "    yearly_count = df.groupby('Year')[org + '_count'].sum().reset_index()\n",
        "    yearly_count['Organization'] = org\n",
        "    org_frequency = pd.concat([org_frequency, yearly_count])\n",
        "\n",
        "# Melt the DataFrame for visualization\n",
        "org_frequency_melted = pd.melt(org_frequency,\n",
        "                               id_vars=['Year'],\n",
        "                               value_vars=[col for col in df.columns if col.endswith('_count')],\n",
        "                               var_name='Organization',\n",
        "                               value_name='count')\n",
        "\n",
        "# Visualize the frequency of organizations over time\n",
        "fig = px.bar(org_frequency_melted,\n",
        "              x='Year',\n",
        "              y='count',\n",
        "              color='Organization',\n",
        "              title='Frequency of Specific Policies Over Time',\n",
        "              labels={'count': 'Frequency', 'Year': 'Year'},\n",
        "              template='plotly_dark')\n",
        "\n",
        "fig.update_layout(\n",
        "    annotations=[\n",
        "        dict(\n",
        "            text=\"The frequency of specific policy mentions over time in budget speeches.\",\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0, y=1.09,  # Position of subtitle\n",
        "            showarrow=False,\n",
        "            font=dict(size=14, color=\"white\")  # Font size and color for the subtitle\n",
        "        )\n",
        "    ])\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "HRXJ9mPkcIlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy model for NER\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load your budget speeches dataset (replace with your file path)\n",
        "df = pd.read_csv('/content/Speech_20years.csv')\n",
        "df['Speech'] = df['Speech'].fillna('')\n",
        "\n",
        "# Clean column names (if necessary)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Ensure year is properly formatted\n",
        "df['Year'] = df['Year'].astype(str).str.split('-').str[0]\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "\n",
        "# Function to extract organization and person entities\n",
        "def extract_entities(text, org_list, person_list):\n",
        "    doc = nlp(text)\n",
        "    entities = [ent.text for ent in doc.ents if (ent.label_ == \"ORG\" and ent.text in org_list) or (ent.label_ == \"PERSON\" and ent.text in person_list)]\n",
        "    return entities\n",
        "\n",
        "# Define the list of organization names you want to track\n",
        "organization_list = [\"Swachh Bharat\", \"Digital India\", \"Make in India\", \"National Rural Employment Guarantee Scheme\",\n",
        "                     \"Smart Cities\",\"Sarva Siksha Abhiyan\",\"Viksit Bharat\"]\n",
        "\n",
        "# Define the list of person names you want to track\n",
        "person_list = [\"Swachh Bharat\", \"Digital India\", \"Make in India\", \"National Rural Employment Guarantee Scheme\",\n",
        "                     \"Smart Cities\",\"Sarva Siksha Abhiyan\",\"Viksit Bharat\"]\n",
        "\n",
        "# Apply the function to extract these organizations and persons for each speech\n",
        "df['Entities'] = df['Speech'].apply(lambda text: extract_entities(text, organization_list, person_list))\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L6oM_iW7iYJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count occurrences of specific entities (organizations or persons)\n",
        "def count_entities(entities, target_entity):\n",
        "    return entities.count(target_entity)\n",
        "\n",
        "# Create a new DataFrame to store entity (organization/person) frequencies over time\n",
        "entity_frequency = pd.DataFrame()\n",
        "\n",
        "# Loop through each organization and person, and calculate their frequency by year\n",
        "for entity in organization_list + person_list:\n",
        "    df[entity + '_count'] = df['Entities'].apply(lambda x: count_entities(x, entity))\n",
        "    yearly_count = df.groupby('Year')[entity + '_count'].sum().reset_index()\n",
        "    yearly_count['Entity'] = entity\n",
        "    entity_frequency = pd.concat([entity_frequency, yearly_count])\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "entity_frequency.tail()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OvJPsVicjSYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}